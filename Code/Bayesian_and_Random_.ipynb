{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EFT0ti2O6pxn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from hyperopt import fmin, rand, hp, STATUS_OK, Trials\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the IMDB dataset with 25,000 labeled reviews\n",
        "(X_train_full, y_train_full), (X_test, y_test) = imdb.load_data(num_words=5000)\n",
        "\n",
        "# Split the dataset into a training set of 20,000 reviews and a validation set of 5,000 reviews\n",
        "X_train = X_train_full[:20000]\n",
        "y_train = y_train_full[:20000]\n",
        "X_val = X_train_full[20000:25000]\n",
        "y_val = y_train_full[20000:25000]\n",
        "\n",
        "# Define the search space for hyperparameters\n",
        "space = {\n",
        "    'alpha': hp.uniform('alpha', 0.001, 0.01),\n",
        "    'numHidden': hp.quniform('numHidden', 16, 256, 16),\n",
        "    'numEpochs': hp.quniform('numEpochs', 1, 10, 1),\n",
        "    'maxLength': hp.quniform('maxLength', 100, 300, 20)\n",
        "}\n",
        "\n",
        "# Define the objective function to optimize\n",
        "def objective(params):\n",
        "    alpha = params['alpha']\n",
        "    numHidden = int(params['numHidden'])\n",
        "    numEpochs = int(params['numEpochs'])\n",
        "    maxLength = int(params['maxLength'])\n",
        "\n",
        "    # Preprocess the data\n",
        "    X_train_padded = pad_sequences(X_train, maxlen=maxLength)\n",
        "    X_val_padded = pad_sequences(X_val, maxlen=maxLength)\n",
        "\n",
        "    # Build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(5000, numHidden, input_length=maxLength))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=alpha), metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_padded, y_train, validation_data=(X_val_padded, y_val), epochs=numEpochs, batch_size=32, verbose=0)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, acc = model.evaluate(X_val_padded, y_val)\n",
        "\n",
        "    return {'loss': -acc, 'status': STATUS_OK}\n",
        "\n",
        "# Run the optimization\n",
        "trials = Trials()\n",
        "best = fmin(objective, space, algo=rand.suggest, max_evals=15, trials=trials)\n",
        "\n",
        "print('Best hyperparameters:', best)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ckuGy-UMJOr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the IMDB dataset with 25,000 labeled reviews\n",
        "(X_train_full, y_train_full), (X_test, y_test) = imdb.load_data(num_words=5000)\n",
        "\n",
        "# Split the dataset into a training set of 20,000 reviews and a validation set of 5,000 reviews\n",
        "X_train = X_train_full[:20000]\n",
        "y_train = y_train_full[:20000]\n",
        "X_val = X_train_full[20000:25000]\n",
        "y_val = y_train_full[20000:25000]\n",
        "\n",
        "# Define the search space for hyperparameters\n",
        "space = {\n",
        "    'alpha': hp.uniform('alpha', 0.001, 0.01),\n",
        "    'numHidden': hp.quniform('numHidden', 16, 511, 16),\n",
        "    'numEpochs': hp.quniform('numEpochs', 1, 15, 1),\n",
        "    'maxLength': hp.quniform('maxLength', 100, 511, 20)\n",
        "}\n",
        "\n",
        "# Define the objective function to optimize\n",
        "def objective(params):\n",
        "    alpha = params['alpha']\n",
        "    numHidden = int(params['numHidden'])\n",
        "    numEpochs = int(params['numEpochs'])\n",
        "    maxLength = int(params['maxLength'])\n",
        "\n",
        "    # Preprocess the data\n",
        "    X_train_padded = pad_sequences(X_train, maxlen=maxLength)\n",
        "    X_val_padded = pad_sequences(X_val, maxlen=maxLength)\n",
        "\n",
        "    # Build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(5000, numHidden, input_length=maxLength))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=alpha), metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_padded, y_train, validation_data=(X_val_padded, y_val), epochs=numEpochs, batch_size=32, verbose=0)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, acc = model.evaluate(X_val_padded, y_val)\n",
        "\n",
        "    return {'loss': -acc, 'status': STATUS_OK}\n",
        "\n",
        "# Run the optimization\n",
        "trials = Trials()\n",
        "best = fmin(objective, space, algo=tpe.suggest, max_evals=15, trials=trials)\n",
        "\n",
        "print('Best hyperparameters:', best)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WnqdesMgrac9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}